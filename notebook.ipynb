# ===============================
# IMPORTS
# ===============================
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from sklearn.metrics import confusion_matrix
import seaborn as sns

# ===============================
# SEED
# ===============================
SEED = 20240211
torch.manual_seed(SEED)
np.random.seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed(SEED)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ===============================
# DATA
# ===============================
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

train_dataset = datasets.SVHN(root='./data', split='train', download=True, transform=transform)
test_dataset  = datasets.SVHN(root='./data', split='test', download=True, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)

# ===============================
# MODEL
# ===============================
class CNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )

        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 4 * 4, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, 10)
        )

    def forward(self, x):
        x = self.features(x)
        return self.classifier(x)

# ===============================
# TRAIN & EVAL
# ===============================
def train_model(lr):
    model = CNN().to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()

    train_accs = []

    for epoch in range(10):
        correct, total = 0, 0
        model.train()
        for x, y in train_loader:
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            out = model(x)
            loss = criterion(out, y)
            loss.backward()
            optimizer.step()

            _, pred = out.max(1)
            correct += (pred == y).sum().item()
            total += y.size(0)

        acc = correct / total
        train_accs.append(acc)
        print(f"Epoch {epoch+1}: Accuracy={acc:.4f}")

    return model, train_accs

# ===============================
# TRAIN TWO VERSIONS
# ===============================
model_v1, acc_v1 = train_model(0.001)
model_v2, acc_v2 = train_model(0.0001)

# ===============================
# PLOT COMPARISON
# ===============================
plt.plot(acc_v1, label="LR=0.001")
plt.plot(acc_v2, label="LR=0.0001")
plt.legend()
plt.title("Training Accuracy Comparison")
plt.savefig("results/training_comparison.png")
plt.show()

# ===============================
# CONFUSION MATRIX
# ===============================
model_v2.eval()
y_true, y_pred = [], []

with torch.no_grad():
    for x, y in test_loader:
        x = x.to(device)
        out = model_v2(x)
        _, pred = out.max(1)
        y_true.extend(y.numpy())
        y_pred.extend(pred.cpu().numpy())

cm = confusion_matrix(y_true, y_pred)
sns.heatmap(cm, annot=False, cmap="Blues")
plt.title("Confusion Matrix")
plt.savefig("results/confusion_matrix.png")
plt.show()
